<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />

    <title>åˆ©ç”¨ä¿¡æ¯æ£€ç´¢çš„è‡ªåŠ¨æ–­è¨€ç”Ÿæˆå’Œå®ƒä¸æ·±åº¦å­¦ä¹ çš„é›†æˆ</title>
    <link rel="shortcut icon" href="./favicon.ico" />
    <link rel="stylesheet" href="./dist/reset.css" />
    <link rel="stylesheet" href="./dist/reveal.css" />
    <link rel="stylesheet" href="./dist/theme/solarized.css" id="theme" />
    <link rel="stylesheet" href="./css/highlight/base16/zenburn.css" />


  </head>
  <body>
    <div class="reveal">
      <div class="slides"><section  data-markdown><script type="text/template">
<style type="text/css"> 
h1,h2,p,ul,li { text-align: left; } 
src {float: left}
</style> 

## <p align="center">Automated Assertion Generation via Infomation Retrieval and Its Integration with Deep Learning</p>
<br/>
<ul>
    <li>Authors:&emsp;Hao Yu,Yiling Lou,Ke Sun,Dezhi Ran,etc.</li>
    <li>Published in:&emsp;ICSE'22</li>
    <li>keywords:&emsp;Unit Testing, Information Retrieval, Test Assertion, Deep Learning</li>
</ul>
<br/><br/>
<div align="right">æ±‡æŠ¥äººï¼šç‹å°å¨… &emsp; &emsp;</div>
<div align="right">æ±‡æŠ¥æ—¶é—´ï¼š2022.11.2</div>
---

<h1>Outline</h1>
<h2>1. Introduction</h2>
<h2>2. Approach</h2>
<h2>3. Experiment</h2>
<h2>4. Conclusion</h2>
<h2>5. Threats to Validity</h2>

---

<h1>1. Introduction</h1>

---

<p>&emsp;unit test case = prefix + oracle</p>
<p>&emsp;assertion is the commonest oracle</p>

```
1:	@Test(timeout=4000)
2:	public void testGetRoot() {
3:		Heap_Item<Integer> item0 = new Heap_Item<Integer>(0);
4:		Pairing_Heap<Integer> ph = new Pairing_Heap<Integer>(item0);
5:		assertSame(item0,ph.getRoot());
6:	}
```

<br/>

### <p>&emsp;approachs of generating assertions</p>
<p>&emsp;&emsp;1. Capture and assert&emsp;(e.g. Randoop and EvoSuite)</p>
<p>&emsp;&emsp;2. Differential testing&emsp;(e.g. DiffGen)</p>
<p>&emsp;&emsp;3. DL based&emsp;(e.g. ATLAS ( <u>A</u>u<u>T</u>omatic <u>L</u>earning of <u>A</u>ssert <u>S</u>tatements ) ICSE'20)</p>

---

***<p>&emsp;Merits of ATLAS</p>***
<p>&emsp;&emsp;1. Can generate assertions for detecting non-crashing faults</p>
<p>&emsp;&emsp;2. For the code under test in form of source code</p>

<br/>

***<p>&emsp;Demerits of ATLAS</p>***
<p>&emsp;&emsp;1. Un-explainable</p>
<p>&emsp;&emsp;2. Poor effectiveness of long assertions</p>

```
assertEquals("-4 -3 -2 -1 0 1 2 3 4",bstTree.serializeInfix());
```

---

<h2>2. Approach</h2>

---

## <p>1. An approach based on information retrieval</p>
<p>&emsp;step1. The technique of IR-based assertion retrieval</p>
<p>&emsp;step2. The technique of retrieved-assertion adaption</p>

## <p>2. Integration approach</p>
<p>&emsp;Integrating IR-based approach and ATLAS</p>

---

## <p>IR-based approach</p>

---
<div>an introduction to focal test</div>
<br/>

```
//focal-test: 
testReport(){ 
  java.lang.String drl="ruleâ£Xâ£date -effectiveâ£\"9-asbrdfh -1974\"â£ when\n"+ (("\$s:â£String()"+"then\n") + "end\n"); 
  org.kie.internal.builder.KnowledgeBuilder kb = org.kie.internal.builder.KnowledgeBuilderFactory.newKnowledgeBuilder(); 
  kb.add(new org.drools.core.io.impl.ByteArrayResource(drl.getBytes()), ResourceType.DRL); 
} 
hasErrors(){ 
  return (errors) != null; 
} 
//Assertion to generate: 
org.junit.Assert.assertTrue(kb.hasErrors())
```

---

*<p>IR-based Assertion Retrieval ğ¼ğ‘…ğ‘ğ‘Ÿ - basic idea</p>*
<br/>
<p>To retrieve the assertion whose corresponding focal-test has the highest similarity with the given focal-test.</p>
<p>Details in next page</p>

---

*<p>Algorithm 1 IR-based Assertion Retrieval ğ¼ğ‘…ğ‘ğ‘Ÿ </p>*
<br/>
```
Input: ğ‘‡ğ‘’ğ‘ ğ‘¡ğ‘“ : the focal-test to generate assertion for. 
Input: ğ‘‡ğ‘Ÿğ‘ğ‘–ğ‘›ğ¹ : all focal-tests in the training set. 
Input: ğ‘‡ğ‘Ÿğ‘ğ‘–ğ‘›ğ´: all corresponding assertions in the training set. 
Output: ğ‘…ğ‘’ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘£ğ‘’ğ‘‘ğ‘“ : the focal-test retrieved by ğ¼ğ‘…ğ‘ğ‘Ÿ . 
Output: ğ‘…ğ‘’ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘£ğ‘’ğ‘‘ğ‘: the assertion retrieved by ğ¼ğ‘…ğ‘ğ‘Ÿ . 

 1: ğ‘šğ‘ğ‘¥ â† 0 , ğ‘…ğ‘’ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘£ğ‘’ğ‘‘ğ‘“ â† â€œâ€, ğ‘…ğ‘’ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘£ğ‘’ğ‘‘ğ‘ â† â€œâ€ 
 2: for ğ‘– = 1 to ğ‘™ğ‘’ğ‘›(ğ‘‡ğ‘Ÿğ‘ğ‘–ğ‘›ğ¹ ) do 
 3:     ğ‘—ğ‘ğ‘ğ‘ğ‘ğ‘Ÿğ‘‘ â† ğ‘ğ‘œğ‘šğ‘ğ‘¢ğ‘¡ğ‘’ (ğ‘‡ğ‘’ğ‘ ğ‘¡ğ‘“ ,ğ‘‡ğ‘Ÿğ‘ğ‘–ğ‘›ğ¹ [ğ‘–]) 
 4:     if ğ‘—ğ‘ğ‘ğ‘ğ‘ğ‘Ÿğ‘‘ > ğ‘šğ‘ğ‘¥ then 
 5:         ğ‘šğ‘ğ‘¥ â† ğ‘—ğ‘ğ‘ğ‘ğ‘ğ‘Ÿğ‘‘ 
 6:         ğ‘…ğ‘’ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘£ğ‘’ğ‘‘ğ‘“ â† ğ‘‡ ğ‘Ÿğ‘ğ‘–ğ‘›ğ¹ [ğ‘–] 
 7:         ğ‘…ğ‘’ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘£ğ‘’ğ‘‘ğ‘ â† ğ‘‡ ğ‘Ÿğ‘ğ‘–ğ‘›ğ´ [ğ‘–] 
 8: return ğ‘…ğ‘’ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘£ğ‘’ğ‘‘ğ‘“ , ğ‘…ğ‘’ğ‘¡ğ‘Ÿğ‘–ğ‘’ğ‘£ğ‘’ğ‘‘ğ‘
```

---

<p>However,it is very conmmon for two similar focal-tests to share similar (but not identical) assertions.</p>

---

*<p>Retrieved-Assertion Adaptation RAadapt - basic idea</p>*
<br/>
<p>Change "almost correct" assertions to correct assertions</p>
<p>adaptation procedure can be divided into three steps</p>

1. decide whether the assertion should be modified.
2. decide which token should be modified.
3. decide what value a candidate token should be replaced with.(Addition and deletion are not under consideration for the time being)

<p>tokens fall into three categories: invoked method, variable, constant</p>

---
```
//focal-test: 
should_build_an_entity_with_the_right_name(){
   builder.setName("name"); 
   org.bonitasoft.engine.identity.model.SCustomUserInfoDefinition entity
   = builder.done(); 
}
getName(){ 
  return name;
} 
// Assertion: 
org.junit.Assert.assertEquals("name", entity.getName());
```
```
//focal-test: 
should_build_an_entity_with_the_right_id(){ 
  builder.setId(1L); 
  org.bonitasoft.engine.identity.model.SCustomUserInfoDefinition entity 
  = builder.done(); 
} 
getId(){ 
  return id; 
} 
// Assertion: 
org.junit.Assert.assertEquals(1L, entity.getId());
```
 &emsp;invoked method:&emsp;IM'<sub>t</sub>==[setName,getName]&emsp;IM'<sub>tir</sub>==[setId,getId] <br/>
 <p>two similarity computing strategy : heuristics-based vs neural-network-based</p> 

---

<h2>Integration approach</h2>

<p>The approach based on information retrieval could be highly effective when there are similar cases in the training set</p>
<p>DL-based approach is capable of generating "new" assertions absent from the training set</p>
<p>Why not combine the two?</p>

---

## Workflow of the integration approach
<img src="pictures/integration.jpg" alt="">
<p>If the semantic compatibility adapted assertion is not high enough, then choose the DL-based generated assertion.</p>

---

<h2>3. Experiment</h2>

---

<h2>dataset</h2>
<br/>
<p>Data<sub>old</sub> : original dataset used by ATLAS &emsp;&emsp;--156,760 data items</p>
<br/>
<p>Data<sub>new</sub> : based on Data<sub>old</sub>, adding cases with unkonwn(absent from the focal-test and vocabulary) &emsp;&emsp;--265,420 data items</p>

---

## *<p>metrics</p>*
<br/>
<p>Accuracy:&emsp;only the assertion that is same with ground truth would be considered as accurate.</p>
<br/>
<p>BLEU:&emsp;evaluate the similarity of generated assertions with the ground truth</p>

---

<h2>Research Questions</h2>
<br/>
<p>RQ1: Effectiveness of IR<sub>ar</sub></p>
<p>RQ2: Effectiveness of RA<sub>adapt</sub></p>
<p>RQ3: Effectiveness of Integration</p>

---
RQ1:Effectiveness of IR<sub>ar</sub>
<br/>
<img src="pictures/table2.jpg" alt="">
<img src="pictures/table3.jpg" alt="">

---

<p>&emsp;&emsp;&emsp;&emsp;Detailed statistics of ATLAS and IR<sub>ar</sub> for each assert type</p>
<img src="pictures/table4.jpg" alt="">

---

<p>Edit distance between correct assertions and incorrect assertions generated</p> 
<p>by ATLAS and IR<sub>ar</sub></p>
<img src="pictures/table6.jpg" alt="">

---

RQ2:Effectiveness of RA<sub>adapt</sub>
<br/>
<img src="pictures/table8.jpg" alt="">

---

RQ3:Effectiveness of Integration
<br/>
<img src="pictures/figure3.jpg" alt="">

---

<img src="pictures/figure4.jpg" alt="">

---

<h2>4. Conclusion</h2>
<p>What did authors try to accomplish?Did they accomplish?</p>
<p>Key elements of the approach.</p>

---
## Workflow of the integration approach
<img src="pictures/integration.jpg" alt="">
---

<h2>5. Threat to validity</h2>
<br/>
<p>compilable and can defect bug?</p>

---

# Thanks for watching
</script></section></div>
    </div>

    <script src="./dist/reveal.js"></script>

    <script src="./plugin/markdown/markdown.js"></script>
    <script src="./plugin/highlight/highlight.js"></script>
    <script src="./plugin/zoom/zoom.js"></script>
    <script src="./plugin/notes/notes.js"></script>
    <script src="./plugin/math/math.js"></script>
    <script>
      function extend() {
        var target = {};
        for (var i = 0; i < arguments.length; i++) {
          var source = arguments[i];
          for (var key in source) {
            if (source.hasOwnProperty(key)) {
              target[key] = source[key];
            }
          }
        }
        return target;
      }

      // default options to init reveal.js
      var defaultOptions = {
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'default', // none/fade/slide/convex/concave/zoom
        plugins: [
          RevealMarkdown,
          RevealHighlight,
          RevealZoom,
          RevealNotes,
          RevealMath
        ]
      };

      // options from URL query string
      var queryOptions = Reveal().getQueryHash() || {};

      var options = extend(defaultOptions, {"width":1520,"height":950,"margin":0.04,"progress":true,"slideNumber":true}, queryOptions);
    </script>


    <script>
      Reveal.initialize(options);
    </script>
  </body>
</html>
